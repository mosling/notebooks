{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae90319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T10:51:52.739728Z",
     "iopub.status.busy": "2021-10-15T10:51:52.738735Z",
     "iopub.status.idle": "2021-10-15T10:51:53.277235Z",
     "shell.execute_reply": "2021-10-15T10:51:53.277235Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from pathlib import Path\n",
    "from os.path import isfile, join\n",
    "from sqlalchemy import create_engine\n",
    "from stringcase import snakecase\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa17bc",
   "metadata": {},
   "source": [
    "Additional installations\n",
    "* psycopg2 for using postgresql with sqlalchemy\n",
    "* openpyxl to access excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226dae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(n):\n",
    "    d = {\"ö\":\"oe\", \"ü\":\"ue\", \"ä\":\"ae\", \"Ä\":\"Ae\", \"Ö\":\"Oe\", \"Ü\":\"Ue\", \n",
    "         \"ß\":\"ss\", \"/\": \"_\", \"=\": \"_\", \" \":\"_\"}\n",
    "    # convert german characters\n",
    "    n = \"\".join([ d.get(c, c) for c in n ])\n",
    "    # replace all blocks of uppercase characters in capitalized block, to prepare snakecase conversion\n",
    "    for f in re.findall(\"([A-Z]+)\", n):\n",
    "        n = n.replace(f, f.lower().capitalize())\n",
    "    # convert to snakecase \n",
    "    n = snakecase(n)\n",
    "    # remove consecutive blocks of underlines\n",
    "    return re.sub('_+','_',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f46d1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_excel_to_database(db_connection, db_schema, excel_file):\n",
    "    engine = create_engine(db_connection)\n",
    "    # list of excel sheets\n",
    "    xl = pd.ExcelFile(excel_file)\n",
    "    table_list = xl.sheet_names\n",
    "    xl.close()\n",
    "    # import each sheet into a database table\n",
    "    for gdata in table_list:\n",
    "        if gdata.startswith(\"_\"):\n",
    "            print(f\"Ignore Excel Sheet '{gdata}' (starts with underline)\")\n",
    "            continue\n",
    "        table_name = normalize_name(gdata)\n",
    "        print(f\"Import Excel Sheet '{gdata}' to Table '{table_name}'\")\n",
    "        df = pd.read_excel (excel_file, sheet_name=gdata).fillna(0)\n",
    "        all_cols = list(df.columns)\n",
    "        df.drop(df.filter(regex='=').columns, axis=1, inplace=True)\n",
    "        rm_cols = [x for x in all_cols if x not in list(df.columns)]\n",
    "        if len(rm_cols) > 0:\n",
    "            print(f\"   remove computed columns (i.e. starts with =): {rm_cols}\")\n",
    "        # modify the column names, because this names are used as SQL column names\n",
    "        df.rename(columns=lambda x : normalize_name(x), inplace=True)\n",
    "        df.to_sql(table_name, engine, schema=db_schema, if_exists=\"replace\", index=False)\n",
    "    engine.dispose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65b89b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_csv_to_database(db_connection, db_schema, csv_file, separator):\n",
    "    engine = create_engine(db_connection)\n",
    "    # get name from CSV file\n",
    "    name = Path(csv_file).stem\n",
    "    table_name = normalize_name(name)\n",
    "    print(f\"Import CSV file '{name}' to Table '{table_name}'\")\n",
    "    df = pd.read_csv(csv_file, dtype=str, sep=separator).fillna(\"\")\n",
    "    # modify the column names, because this names are used as SQL column names\n",
    "    df.rename(columns=lambda x : normalize_name(x), inplace=True)\n",
    "    df.to_sql(table_name, engine, schema=db_schema, if_exists=\"replace\", index=False)\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04a4fa5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T10:51:53.281223Z",
     "iopub.status.busy": "2021-10-15T10:51:53.281223Z",
     "iopub.status.idle": "2021-10-15T10:51:53.323009Z",
     "shell.execute_reply": "2021-10-15T10:51:53.324038Z"
    }
   },
   "outputs": [],
   "source": [
    "def folder_files(path_name, file_pattern):    \n",
    "    return [ join(path_name, x) for x in listdir(path_name) if (isfile(join(path_name, x)) and re.match(file_pattern, x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd4b8b",
   "metadata": {},
   "source": [
    "# Define Database Connection, Folder and File Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e782f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_connection = \"postgresql://postgres:postgres@localhost:5432/tavee\"\n",
    "db_connection = \"postgresql://postgres:postgres@localhost:5432/inetz_bis_strom\"\n",
    "db_schema = \"public\"\n",
    "\n",
    "folder = r\"C:\\Users\\koehler_s\\project\\chemnitz-inetz\\bis_strom_mapping\\netzanschluss\"\n",
    "file_pattern = r\".*\\.csv\"\n",
    "#folder = r\"C:\\Users\\koehler_s\\project\\eisenach-tavee\\oracle-daten\"\n",
    "#file_pattern = \"tbm_wa_entlueftung.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a065650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T10:51:53.328031Z",
     "iopub.status.busy": "2021-10-15T10:51:53.327000Z",
     "iopub.status.idle": "2021-10-15T10:51:53.805220Z",
     "shell.execute_reply": "2021-10-15T10:51:53.804243Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import CSV file 'bis_hak' to Table 'bis_hak'\n",
      "Import CSV file 'bis_sonderverbraucher' to Table 'bis_sonderverbraucher'\n",
      "Import CSV file 'tbm_hak' to Table 'tbm_hak'\n",
      "Import CSV file 'tbm_sonderverbraucher' to Table 'tbm_sonderverbraucher'\n"
     ]
    }
   ],
   "source": [
    "for fn in folder_files(folder, file_pattern):\n",
    "    # copy_excel_to_database(db_connection, db_schema, fn)\n",
    "    copy_csv_to_database(db_connection, db_schema, fn, \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37322fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
